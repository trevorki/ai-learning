{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Embeddings\n",
    "Just like how words can be converted to vectors, so can sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "import json\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Embeddings\n",
    "There are a variety of ways to embed entire sentences. \n",
    "\n",
    "- take the average of all of the words' embedding\n",
    "- use a more sophisticated embedding model like BERT\n",
    "\n",
    "### Average the word embeddings\n",
    "The simplest way is to take the embedding of each word then average them together. This seems silly, but it is pretty effective. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from binary: models/word2vec-google-news-300.bin\n"
     ]
    }
   ],
   "source": [
    "# Use small local model \n",
    "model_name = 'word2vec-google-news-300'\n",
    "w2v_model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_sentence_average(sentence, w2v_model):\n",
    "    \"\"\"Creates sentence embedding based on the average of the words' embeddings\"\"\"\n",
    "    # split sentence into words\n",
    "    words = sentence.split()\n",
    "    \n",
    "    # make array of embeddings, one row for each word\n",
    "    embeddings = np.array([w2v_model[w.lower()] for w in words if w in w2v_model])\n",
    "    \n",
    "    # average over the rows (axis = 0)\n",
    "    average_embedding = embeddings.mean(axis = 0)\n",
    "    \n",
    "    return average_embedding\n",
    "\n",
    "def cosine_similarity(A, B):\n",
    "    \"\"\"Calculates the cosine similarity of 2 vectors A,B\"\"\"\n",
    "    dot_product = np.dot(A, B)\n",
    "    magnitude_A = np.linalg.norm(A)\n",
    "    magnitude_B = np.linalg.norm(B)\n",
    "    return dot_product / (magnitude_A * magnitude_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I love cookies\"\n",
    "embedding = embed_sentence_average(sentence, w2v_model)\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7167495"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_1 = \"I love cookies\"\n",
    "sentence_2 = \"cookies are my favorite\"\n",
    "\n",
    "embedding_1 = embed_sentence_average(sentence_1, w2v_model)\n",
    "embedding_2 = embed_sentence_average(sentence_2, w2v_model)\n",
    "\n",
    "cosine_similarity(embedding_1, embedding_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1749812"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_1 = \"I love cookies\"\n",
    "sentence_2 = \"that car is speeding in the school zone\"\n",
    "\n",
    "embedding_1 = embed_sentence_average(sentence_1, w2v_model)\n",
    "embedding_2 = embed_sentence_average(sentence_2, w2v_model)\n",
    "\n",
    "cosine_similarity(embedding_1, embedding_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24969348"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that we can also use gensim's n_similarity() funtion to do the same\n",
    "w2v_model.n_similarity(sentence_1.split(),sentence_2.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"720px\"\n",
       "    height=\"620\"\n",
       "    src=\"iframe_figures/figure_8.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's visualize defferent sentence embeddings in a PCA-reduced 3d space\n",
    "sentences = [\n",
    "    \"cookies are my favorite\",\n",
    "    \"cookies are a glorious dessert\",\n",
    "    \"my, how I love biscuits\",\n",
    "    \"I am a huge cookie lover\",\n",
    "    \"Cookies are delicious\",\n",
    "    \"summer vacation is coming\",\n",
    "    \"where should we go on vacation\",\n",
    "    \"the motorcycle can go very fast\", \n",
    "    \"that car speeding in the school zone\"\n",
    "]\n",
    "embeddings = [embed_sentence_average(sentence, w2v_model) for sentence in sentences]\n",
    "embeddings_reduced = reduce_dimensions(embeddings)\n",
    "plot_embeddings(embeddings_reduced, sentences, title=\"Average sentence embeddings (reduced to 3D)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between I love cookies and :\n",
      "\t0.72 : cookies are my favorite\n",
      "\t0.66 : cookies are a glorious dessert\n",
      "\t0.79 : my, how I love biscuits\n",
      "\t0.73 : I am a huge cookie lover\n",
      "\t0.67 : Cookies are delicious\n",
      "\t0.19 : summer vacation is coming\n",
      "\t0.31 : where should we go on vacation\n",
      "\t0.29 : the motorcycle can go very fast\n",
      "\t0.17 : that car speeding in the school zone\n"
     ]
    }
   ],
   "source": [
    "# similarity between one word and many others\n",
    "sentence = \"I love cookies\"\n",
    "embedding = embed_sentence_average(sentence, w2v_model)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Similarity between {sentence} and :\")\n",
    "for other_sentence in sentences:\n",
    "    other_embedding = embed_sentence_average(other_sentence, w2v_model)\n",
    "    similarity = cosine_similarity(embedding, other_embedding)\n",
    "    print(f\"\\t{similarity:.2f} : {other_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations of average embeddings\n",
    "A drawback is that this method does not take into account the order of the words, which is very important to the meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_1 = \"I love cats and hate dogs\"\n",
    "sentence_2 = \"I love dogs and hate cats\"\n",
    "w2v_model.n_similarity(sentence_1.split(),sentence_2.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_1 = embed_sentence_average(sentence_1, w2v_model)\n",
    "embedding_2 = embed_sentence_average(sentence_2, w2v_model)\n",
    "\n",
    "cosine_similarity(embedding_1, embedding_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced methods\n",
    "We can use a language model to predict the next word in a sentence. \n",
    "\n",
    "Here we will a sentence transformer embedding model that can be run locally using the Transformers library. The process is a little involved and we won't get into it here. This will produce a 768-dimension embedding vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Trevor_Kinsey\\miniconda3\\envs\\edu\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning:\n",
      "\n",
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "\n",
      "C:\\Users\\Trevor_Kinsey\\miniconda3\\envs\\edu\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning:\n",
      "\n",
      "`resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I love cats and hate dogs\"\n",
    "\n",
    "\n",
    "embeddings1 = model.encode(sentence)\n",
    "embeddings1.shape\n",
    "# similarities = model.similarity(embeddings1, embeddings2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_1 = \"I love cats and hate dogs\"\n",
    "# sentence_2 = \"I don't like dogs and love cats\"\n",
    "# sentence_2 = \"I don't like dogs and love cats\"\n",
    "sentence_2 = \"eat my shorts\"\n",
    "# sentence_2 = \"I love dogs and hate cats\"\n",
    "\n",
    "embedding_1 = model.encode(sentence_1)\n",
    "embedding_2 = model.encode(sentence_1)\n",
    "\n",
    "similarity = model.similarity(embedding_1, embedding_2)\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between I love cookies and :\n",
      "\t0.88 : cookies are my favorite\n",
      "\t0.73 : cookies are a glorious dessert\n",
      "\t0.60 : my, how I love biscuits\n",
      "\t0.77 : I am a huge cookie lover\n",
      "\t0.82 : Cookies are delicious\n",
      "\t0.11 : summer vacation is coming\n",
      "\t0.10 : where should we go on vacation\n",
      "\t0.07 : the motorcycle can go very fast\n",
      "\t0.01 : that car speeding in the school zone\n"
     ]
    }
   ],
   "source": [
    "# similarity between one word and many others\n",
    "sentence = \"I love cookies\"\n",
    "embedding = model.encode(sentence)\n",
    "\n",
    "print(f\"Similarity between {sentence} and :\")\n",
    "for other_sentence in sentences:\n",
    "    other_embedding = model.encode(other_sentence)\n",
    "    similarity = cosine_similarity(embedding, other_embedding)\n",
    "    print(f\"\\t{similarity:.2f} : {other_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval\n",
    "The concept of similarity is useful in the context of retrieval augmented generation (RAG). \n",
    "Rag is useful when you have a lot of documents that you would like to ask questions of with an LLM. Typicaly the LLM has no knowledge of your documents so you need to *retrieve* the relevant info from your documents and send it to the LLM\n",
    "\n",
    "The idea is you ask a question, embed the question, then retrieve your documents that are closest to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_most_similar(query, names, descriptions, embeddings, n=5):\n",
    "    \"\"\"\n",
    "    Retrieves the most similar items to a given query based on their embeddings.\n",
    "\n",
    "    Parameters:\n",
    "    query (str): The query to compare against.\n",
    "    names (List[str]): The names of the items.\n",
    "    descriptions (List[str]): The descriptions of the items.\n",
    "    embeddings (List[np.ndarray]): The embeddings of the items.\n",
    "    n (int, optional): The number of most similar items to return. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame sorted by similarity to the query, containing the top n most similar items.\n",
    "    \"\"\"\n",
    "    embedded_query = model.encode(query)\n",
    "    similarities = []\n",
    "    for embedding in embeddings:\n",
    "        similarities.append(cosine_similarity(embedded_query, embedding))\n",
    "    df = pd.DataFrame({\n",
    "        \"similarity\": similarities,\n",
    "        \"name\": names,\n",
    "        \"description\": descriptions\n",
    "    })\n",
    "    return df.sort_values(\"similarity\", ascending = False).head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "Let's load some data about pokemon characters from a json file that I asked Claude-3.5 Sonnet to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Pikachu',\n",
       " 'description': \"Pikachu is an iconic Electric-type Pokemon resembling a yellow mouse. It has red cheeks that store electricity and a lightning bolt-shaped tail. Pikachu is known for its ability to generate powerful electric shocks. It's the mascot of the Pokemon franchise and a popular starter Pokemon for many trainers.\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/pokemon.json\") as f:\n",
    "    pokemon_info = json.load(f)\n",
    "\n",
    "# look at the first one\n",
    "pokemon_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [item[\"name\"] for item in pokemon_info]\n",
    "descriptions = [item[\"description\"] for item in pokemon_info]\n",
    "embeddings = [model.encode(item[\"description\"]) for item in pokemon_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: 'which pokemon can fly?'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.481414</td>\n",
       "      <td>Charizard</td>\n",
       "      <td>Charizard is a powerful Fire/Flying-type Pokem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.461601</td>\n",
       "      <td>Blaziken</td>\n",
       "      <td>Blaziken is a Fire/Fighting-type Pokemon that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.461312</td>\n",
       "      <td>Magikarp</td>\n",
       "      <td>Magikarp is a Water-type Pokemon infamous for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.449819</td>\n",
       "      <td>Gyarados</td>\n",
       "      <td>Gyarados is a fearsome Water/Flying-type Pokem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.449307</td>\n",
       "      <td>Dragonite</td>\n",
       "      <td>Dragonite is a powerful Dragon/Flying-type Pok...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    similarity       name                                        description\n",
       "1     0.481414  Charizard  Charizard is a powerful Fire/Flying-type Pokem...\n",
       "26    0.461601   Blaziken  Blaziken is a Fire/Fighting-type Pokemon that ...\n",
       "14    0.461312   Magikarp  Magikarp is a Water-type Pokemon infamous for ...\n",
       "4     0.449819   Gyarados  Gyarados is a fearsome Water/Flying-type Pokem...\n",
       "15    0.449307  Dragonite  Dragonite is a powerful Dragon/Flying-type Pok..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"which pokemon can fly?\"\n",
    "print(f\"query: '{query}'\")\n",
    "df_similar = retrieve_most_similar(query, names, descriptions, embeddings, n=5)\n",
    "df_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Charizard is a powerful Fire/Flying-type Pokemon that evolves from Charmeleon. It resembles a large, orange dragon with wings and a flame burning at the tip of its tail. Charizard can breathe intense flames and fly at great speeds. It's known for its fierce battles and loyalty to its trainer. \n",
      "\n",
      "2 Blaziken is a Fire/Fighting-type Pokemon that evolves from Combusken. It has a bird-like appearance with powerful legs and fiery wrists. Blaziken is known for its incredible jumping ability and powerful kicks that can shatter skyscrapers. It's often seen as a representation of determination and fighting spirit. \n",
      "\n",
      "3 Magikarp is a Water-type Pokemon infamous for being weak and useless in battle. It resembles a large, orange fish and is known for its inability to learn many moves. However, Magikarp evolves into the powerful Gyarados, embodying the theme of hidden potential. It's often used as an example of how seemingly weak Pokemon can become strong. \n",
      "\n",
      "4 Gyarados is a fearsome Water/Flying-type Pokemon that evolves from the seemingly weak Magikarp. It resembles a large, serpentine dragon with a gaping mouth. Gyarados is known for its destructive power and ability to cause massive storms. It represents the concept of perseverance and hidden potential. \n",
      "\n",
      "5 Dragonite is a powerful Dragon/Flying-type Pokemon with a friendly appearance. It resembles a large, orange dragon with small wings. Despite its intimidating size, Dragonite is known for its gentle and helpful nature. It can fly around the world in just 16 hours and is said to live in the sea. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, description in enumerate(df_similar[\"description\"], start=1):\n",
    "    print(i, description, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So these results aren't the best, but we'll do better in a later notebook on RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:edu]",
   "language": "python",
   "name": "conda-env-edu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
